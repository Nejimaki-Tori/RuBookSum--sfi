\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{\url{https://doi.org/#1}}

\bibitem{blueprint}
Huot, F., Maynez, J., Narayan, S., et~al.: Text-blueprint: An interactive
  platform for plan-based conditional generation. In: Croce, D., Soldaini, L.
  (eds.) Proceedings of the 17th Conference of the European Chapter of the
  Association for Computational Linguistics: System Demonstrations. pp.
  105--116. Association for Computational Linguistics, Dubrovnik, Croatia (May
  2023). \doi{10.18653/v1/2023.eacl-demo.13}

\bibitem{fables}
Kim, Y., Chang, Y., Karpinska, M., et~al.: Fables: Evaluating faithfulness and
  content selection in book-length summarization. In: First Conference on
  Language Modeling

\bibitem{BookSum}
Kryscinski, W., Rajani, N., Agarwal, D., et~al.: {BOOKSUM}: A collection of
  datasets for long-form narrative summarization. In: Goldberg, Y., Kozareva,
  Z., Zhang, Y. (eds.) Findings of the Association for Computational
  Linguistics: EMNLP 2022. pp. 6536--6558. Association for Computational
  Linguistics, Abu Dhabi, United Arab Emirates (Dec 2022).
  \doi{10.18653/v1/2022.findings-emnlp.488}

\bibitem{librusec}
{LibRusEc}: Library of works of art. \url{https://librusec.org/} (2025),
  accessed: 2025-07-30

\bibitem{rouge}
Lin, C.Y.: {ROUGE}: A package for automatic evaluation of summaries. In: Text
  Summarization Branches Out. pp. 74--81. Association for Computational
  Linguistics, Barcelona, Spain (Jul 2004),
  \url{https://aclanthology.org/W04-1013/}

\bibitem{deepseek}
Liu, A., et~al.: Deepseek{-}v3 technical report. CoRR  (2024)

\bibitem{Briefly}
{Narodny Briefly}: Digital library of short summaries of literary works.
  \url{https://wiki.briefly.ru/} (2025), accessed: 2025-07-30

\bibitem{alexandria}
Scir{\`e}, A., Conia, S., Ciciliano, S., Navigli, R.: Echoes from alexandria: A
  large resource for multilingual book summarization. In: Rogers, A.,
  Boyd-Graber, J., Okazaki, N. (eds.) Findings of the Association for
  Computational Linguistics: ACL 2023. pp. 853--867. Association for
  Computational Linguistics, Toronto, Canada (Jul 2023).
  \doi{10.18653/v1/2023.findings-acl.54}

\bibitem{tpro}
{T{-}Bank}: T{-}bank has opened access to its own russian{-}language language
  model in the 7--8 billion parameter weight category.
  \url{https://www.tbank.ru/about/news/20072024-t-bank-opened-access-its-own-russian-language-language-model-weight-category-of-7-8-billion-parameters/}
  (2024), accessed: 2025-08-21

\bibitem{ruadapt}
Tikhomirov, M., Chernyshov, D.: Facilitating large language model russian
  adaptation with learned embedding propagation. Journal of Language and
  Education  10(4),  130--145 (Dec 2024). \doi{10.17323/jle.2024.22224}

\bibitem{hierarchical}
Wu, J., Ouyang, L., Ziegler, D.M., et~al.: Recursively summarizing books with
  human feedback (2021), \url{https://arxiv.org/abs/2109.10862}

\bibitem{yagpt}
{Yandex}: Yandexgpt 5 with reasoning mode. \url{https://ya.ru/ai/gpt} (2025),
  accessed: 2025-07-30

\bibitem{qwen3}
Yang, A., et~al.: Qwen3 technical report (2025),
  \url{https://arxiv.org/abs/2505.09388}

\bibitem{bertscore}
Zhang, T., Kishore, V., Wu, F., et~al.: Bertscore: Evaluating text generation
  with bert. In: International Conference on Learning Representations

\end{thebibliography}
